var documenterSearchIndex = {"docs":
[{"location":"api/#Public-API","page":"Public API","title":"Public API","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"These are all of the functions and data structures that the user needs to know in order to use this package.","category":"page"},{"location":"api/#Tree-ensembles","page":"Public API","title":"Tree ensembles","text":"","category":"section"},{"location":"api/#Data-structures","page":"Public API","title":"Data structures","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"TEModel - holds the parameters from a tree ensemble model","category":"page"},{"location":"api/#Tree-model-parameter-extraction","page":"Public API","title":"Tree model parameter extraction","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"extract_evotrees_info - get the necessary parameters from an EvoTrees model","category":"page"},{"location":"api/#MIP-formulation","page":"Public API","title":"MIP formulation","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"TE_formulate! - formulate a JuMP model from a tree ensemble without the split constraints","category":"page"},{"location":"api/#Input-optimization","page":"Public API","title":"Input optimization","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"add_split_constraints! - add all split constraints to the formulation\ntree_callback_algorithm - used to add only necessary split constraints during callbacks","category":"page"},{"location":"api/#Showing-the-solution","page":"Public API","title":"Showing the solution","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"get_solution - get human-readable solution in the form of upper and lower bounds for the input variables","category":"page"},{"location":"api/#Neural-networks","page":"Public API","title":"Neural networks","text":"","category":"section"},{"location":"api/#MIP-formulation-2","page":"Public API","title":"MIP formulation","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"NN_formulate! - formulate a JuMP model, perform simultaneous bound tightening and possibly compression","category":"page"},{"location":"api/#Compression","page":"Public API","title":"Compression","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"NN_compress - compress a neural network using precomputed activation bounds","category":"page"},{"location":"api/#Forward-pass","page":"Public API","title":"Forward pass","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"forward_pass! - fix the input variables and optimize the model to get the output","category":"page"},{"location":"api/#Convolutional-neural-networks","page":"Public API","title":"Convolutional neural networks","text":"","category":"section"},{"location":"api/#Data-structures-2","page":"Public API","title":"Data structures","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"CNNStructure - container for the layer stucture of a convolutional neural network model","category":"page"},{"location":"api/#Parameter-extraction","page":"Public API","title":"Parameter extraction","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"get_structure - get layer structure from a convolutional neural network model","category":"page"},{"location":"api/#MIP-formulation-3","page":"Public API","title":"MIP formulation","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"CNN_formulate! - formulate a JuMP model from the CNN","category":"page"},{"location":"api/#Forward-pass-2","page":"Public API","title":"Forward pass","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"image_pass! - fix the input variables and optimize the model to get the ouput","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"CurrentModule = Gogeta","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [Gogeta]","category":"page"},{"location":"reference/#Gogeta.CNNStructure","page":"Reference","title":"Gogeta.CNNStructure","text":"struct CNNStructure\n\nContainer for the layer structure of a convolutional neural network.\n\nThis structure is used for passing the CNN parameters from one function to another. This structure can be created with the get_structure -function.\n\nFields\n\nchannels: dictionary of (layer, number of channels) pairs for convolutional or pooling layers\ndims: dictionary of (layer, (# of rows, # of columns)) pairs for convolutional or pooling layers\ndense_lengths: dictionary of (layer, # of neurons) pairs for dense and flatten layers\nconv_inds: vector of the convolutional layer indices\nmaxpool_inds_inds: vector of the maxpool layer indices\nmeanpool_inds: vector of the meanpool layer indices\nflatten_ind: index of the Flux.flatten layer\ndense_inds: vector of the dense layer indices\n\n```\n\n\n\n\n\n","category":"type"},{"location":"reference/#Gogeta.TEModel","page":"Reference","title":"Gogeta.TEModel","text":"struct TEModel\n\nUniversal datatype for storing information about a Tree Ensemble Model. This is the datatype that is used when creating the integer optimization problem from a tree ensemble.\n\nDifferent tree models (EvoTrees, XGBoost, RandomForest) require individual conversion functions to this datatype.\n\nFields\n\nn_trees: number of trees in the ensemble\nn_feats: number of features (input variables) in the model\nn_leaves: number of leaves on each tree\nleaves: indices of the leaves on each tree\nsplits: [feature, splitpoint index] pairs accessible by [tree, node]\nsplits_ordered: splitpoints ordered by split value for each feature\nn_splits: number of splitpoints for each feature\npredictions: prediction of each node (zero for nodes that are not leaves)\nsplit_nodes: boolean array containing information whether a node is a split node or not\n\nSplitpoints is the set of unique condition values from the ensemble. Each node is associated with a condition value.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Gogeta.CNN_formulate!-Tuple{JuMP.Model, Flux.Chain, CNNStructure}","page":"Reference","title":"Gogeta.CNN_formulate!","text":"function create_MIP_from_CNN!(jump_model::JuMP.Model, CNN_model::Flux.Chain, cnnstruct::CNNStructure)\n\nCreates a mixed-integer optimization problem from a Flux.Chain convolutional neural network model. The optimization formulation is saved in the JuMP.Model given as an input.\n\nThe convolutional neural network must follow a certain structure:\n\nIt must consist of (in order) convolutional and pooling layers, a Flux.flatten layer and finally dense layers\nI.e. allowed layer types: Conv, MaxPool, MeanPool, Flux.flatten, Dense\nThe activation function for all of the convolutional layers and the dense layers must be ReLU\nThe last dense layer must use the identity activation function\nInput size, filter size, stride and padding can be chosen freely\n\nParameters\n\njump_model: an empty optimization model where the formulation will be saved\nCNN_model: Flux.Chain containing the CNN\ncnnstruct: holds the layer structure of the CNN\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.NN_compress-Tuple{Flux.Chain, Vararg{Any, 4}}","page":"Reference","title":"Gogeta.NN_compress","text":"function NN_compress(NN_model::Flux.Chain, U_in, L_in, U_bounds, L_bounds)\n\nCompresses a neural network using precomputed bounds.\n\nArguments\n\nNN_model: Neural network to be compressed.\nU_in: Upper bounds for the input variables.\nL_in: Lower bounds for the input variables.\nU_bounds: Upper bounds for the other neurons.\nL_bounds: Lower bounds for the other neurons.\n\nReturns a Flux.Chain model of the compressed neural network.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.NN_formulate!-Tuple{JuMP.Model, Flux.Chain, Any, Any}","page":"Reference","title":"Gogeta.NN_formulate!","text":"function NN_formulate!(jump_model::JuMP.Model, NN_model::Flux.Chain, U_in, L_in; U_bounds=nothing, L_bounds=nothing, U_out=nothing, L_out=nothing, bound_tightening=\"fast\", compress=false, parallel=false, silent=true)\n\nCreates a mixed-integer optimization problem from a Flux.Chain model.\n\nThe parameters are used to specify what kind of bound tightening and compression will be used.\n\nArguments\n\njump_model: The constraints and variables will be saved to this optimization model.\nNN_model: Neural network model to be formulated.\nU_in: Upper bounds for the input variables.\nL_in: Lower bounds for the input variables.\n\nOptional arguments\n\nbound_tightening: Mode selection: \"fast\", \"standard\", \"output\" or \"precomputed\"\ncompress: Should the model be simultaneously compressed?\nparallel: Runs bound tightening in parallel. set_solver!-function must be defined in the global scope, see documentation or examples.\nU_bounds: Upper bounds. Needed if bound_tightening=\"precomputed\"\nL_bounds: Lower bounds. Needed if bound_tightening=\"precomputed\"\nU_out: Upper bounds for the output variables. Needed if bound_tightening=\"output\".\nL_out: Lower bounds for the output variables. Needed if bound_tightening=\"output\".\nsilent: Controls console ouput.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.TE_formulate!-Tuple{JuMP.Model, TEModel, Any}","page":"Reference","title":"Gogeta.TE_formulate!","text":"function TE_formulate!(opt_model::JuMP.Model, TE::TEModel, objective)\n\nFormulates a tree ensemble to the JuMP model opt_model based on the given tree ensemble TE.\n\nThe JuMP model is formulated without the split constraints.\n\nArguments\n\nopt_model: A JuMP model where the formulation will be saved to.\nTE: A tree ensemble model in the universal data type TEModel. \nobjective: MINSENSE or MAXSENSE.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.add_split_constraints!-Tuple{JuMP.Model, TEModel}","page":"Reference","title":"Gogeta.add_split_constraints!","text":"function add_split_constraints!(opt_model::JuMP.Model, TE::TEModel)\n\nAdds all split constraints to the formulation.\n\nArguments\n\nopt_model: A JuMP model containing the formulation.\nTE: A tree ensemble model in the universal data type TEModel. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.build_model!-NTuple{4, Any}","page":"Reference","title":"Gogeta.build_model!","text":"function build_model!(W, b, K, neurons)\n\nBuilds a new Flux.Chain model from the given weights and biases. Modifies the W and b arrays.\n\nReturns the new Flux.Chain model.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.calculate_bounds-Tuple{JuMP.Model, Vararg{Any, 5}}","page":"Reference","title":"Gogeta.calculate_bounds","text":"function calculate_bounds(model::JuMP.Model, layer, neuron, W, b, neurons; layers_removed=0)\n\nCalculates the upper and lower activation bounds for a neuron in a ReLU-activated neural network.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.children-Tuple{Int64, Dict, Int64}","page":"Reference","title":"Gogeta.children","text":"function children(id::Int, leaf_dict::Dict, max::Int)\n\nFinds the leaf indices of the children leaves of node id in a binary tree.\n\nReturns an array of the leaf indices.\n\nArguments\n\nid: Index of the node in a binary tree. Indexing starts from one and follows level order.\nleaf_dict: A dictionary (map) of the leaf indices accessible by the node indices.\nmax: Biggest possible node id in the tree. Used to terminate the search.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.copy_model-Tuple{Any}","page":"Reference","title":"Gogeta.copy_model","text":"function copy_model(input_model, solver_params)\n\nCreates a copy of a JuMP model. Solver has to be specified for each new copy. Used for parallelization.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.extract_evotrees_info-Tuple{Any}","page":"Reference","title":"Gogeta.extract_evotrees_info","text":"extract_evotrees_info(evo_model; tree_limit=length(evo_model.trees))\n\nGets the data required for constructing the corresponding MIP from an EvoTrees model evo_model.  Returns a custom datatype TEModel which contains the necessary information.\n\nArguments\n\nevo_model: A trained EvoTrees tree ensemble model.\n\nOptional arguments\n\ntree_limit: only first n trees specified by the argument will be used\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.forward_pass!-Tuple{JuMP.Model, Any}","page":"Reference","title":"Gogeta.forward_pass!","text":"function forward_pass!(jump_model::JuMP.Model, input)\n\nCalculates the output of a JuMP model representing a neural network.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.get_solution-Tuple{JuMP.Model, TEModel}","page":"Reference","title":"Gogeta.get_solution","text":"function get_solution(model::JuMP.Model, TE::TEModel)\n\nFinds the upper and lower bounds for each input variable given the optimized model.\n\nReturns the bounds for each feature in an array.\n\nArguments\n\nmodel: The optimized JuMP model.\nTE: Struct of type TEModel containing information about the tree ensemble.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.get_structure-Tuple{Flux.Chain, Array{Float32, 4}}","page":"Reference","title":"Gogeta.get_structure","text":"function get_structure(CNN_model::Flux.Chain, input::Array{Float32, 4})\n\nExtract the layer structure of a convolutional neural network. The input image is needed to calculate the correct sizes for the hidden 2-dimensional layers.\n\nReturns a CNNStructure struct.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.image_pass!-Tuple{JuMP.Model, Array{Float32, 4}, CNNStructure, Int64}","page":"Reference","title":"Gogeta.image_pass!","text":"function image_pass!(jump_model::JuMP.Model, input::Array{FLoat32, 4}, cnnstruct::CNNStructure, layer::Int)\n\nDebugging version\n\nForward pass an image through the JuMP model representing a convolutional neural network.\n\nReturns the output of the layer with index given as input.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.image_pass!-Tuple{JuMP.Model, Array{Float32, 4}}","page":"Reference","title":"Gogeta.image_pass!","text":"function image_pass!(jump_model::JuMP.Model, input::Array{Float32, 4})\n\nForward pass an image through the JuMP model representing a convolutional neural network.\n\nReturns the output of the network, i.e., a vector of the activations of the last dense layer neurons.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.init_TEModel!-Tuple{TEModel}","page":"Reference","title":"Gogeta.init_TEModel!","text":"function init_TEModel!(TE::TEModel)\n\nPrecompute child leaves which are needed for generating the split constraints. Changes child_leaves field of the TEModel.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.prune!-NTuple{8, Any}","page":"Reference","title":"Gogeta.prune!","text":"function prune!(W, b, removed_neurons, layers_removed, neuron_count, layer, bounds_U, bounds_L)\n\nRemoves stabily active or inactive neurons in a network by updating the weights and the biases and the removed neurons list accordingly.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.tree_callback_algorithm-Tuple{Any, TEModel, JuMP.Model}","page":"Reference","title":"Gogeta.tree_callback_algorithm","text":"function tree_callback_algorithm(cb_data, TE::TEModel, opt_model::JuMP.Model)\n\nThe callback algorithm for tree ensemble optimization using lazy constraints.\n\nUsing lazy constraints, the split constraints are added one-by-one for each tree.\n\nSee examples or documentation for information on how to use lazy constraints.\n\nArguments\n\ncb_data: Callback data\nTE: A tree ensemble model in the universal data type TEModel. \nopt_model: A JuMP model containing the formulation.\n\n\n\n\n\n","category":"method"},{"location":"#Gogeta.jl","page":"Introduction","title":"Gogeta.jl","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Gogeta is a package that enables the user to formulate machine-learning models as mathematical programming problems.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Currently supported models are Flux.Chain ReLU-activated neural networks (dense and convolutional) and EvoTrees tree ensemble models.","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> Pkg.add(\"Gogeta\")","category":"page"},{"location":"#Getting-started","page":"Introduction","title":"Getting started","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The following sections give a very simple demonstration on how to use the package.  Multiprocessing examples and more detailed code can be found in the examples/-folder of the package repository.","category":"page"},{"location":"#Tree-ensembles","page":"Introduction","title":"Tree ensembles","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"First, one must create and train an EvoTrees tree ensemble model.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using EvoTrees\n\nconfig = EvoTreeRegressor(nrounds=500, max_depth=5)\nevo_model = fit_evotree(config; x_train, y_train)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Then the parameters can be extracted from the trained tree ensemble and used to create a JuMP model containing the tree ensemble MIP formulation.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Gurobi\nusing Gogeta\n\n# Extract data from EvoTrees model\n\nuniversal_tree_model = extract_evotrees_info(evo_model)\n\n# Create jump model and formulate\njump = Model(() -> Gurobi.Optimizer())\nset_attribute(jump, \"OutputFlag\", 0) # JuMP or solver-specific attributes can be changed\n\nTE_formulate!(jump, universal_tree_model, MIN_SENSE)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"There are two ways of optimizing the JuMP model: either by 1) creating the full set of split constraints before optimizing, or 2) using lazy constraints to generate only the necessary ones during the solution process.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"1) Full set of constraints","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"add_split_constraints!(jump, universal_tree_model)\noptimize!(jump)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"2) Lazy constraints","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"# Define callback function. For each solver this might be slightly different.\n# See JuMP documentation or your solver's Julia interface documentation.\n# Inside the callback 'tree_callback_algorithm' must be called.\n\nfunction split_constraint_callback_gurobi(cb_data, cb_where::Cint)\n\n    # Only run at integer solutions\n    if cb_where != GRB_CB_MIPSOL\n        return\n    end\n\n    Gurobi.load_callback_variable_primal(cb_data, cb_where)\n    tree_callback_algorithm(cb_data, universal_tree_model, jump)\n\nend\n\njump = direct_model(Gurobi.Optimizer())\nTE_formulate!(jump, universal_tree_model, MIN_SENSE)\n\nset_attribute(jump, \"LazyConstraints\", 1)\nset_attribute(jump, Gurobi.CallbackFunction(), split_constraint_callback_gurobi)\n\noptimize!(jump)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The optimal solution (minimum and maximum values for each of the input variables) can be queried after the optimization.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"get_solution(opt_model, universal_tree_model)\nobjective_value(opt_model)","category":"page"},{"location":"#Neural-networks","page":"Introduction","title":"Neural networks","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"With neural networks, the hidden layers must use the ReLU activation function, and the output layer must use the identity activation.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"These neural networks can be formulated into mixed-integer optimization problems.  Along with formulation, the neuron activation bounds can be calculated, which improves computational performance as well as enables compression.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The network is compressed by pruning neurons that are either stabily active or inactive. The activation bounds are used to identify these neurons.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"First, create a neural network model satisfying the requirements:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Flux\n\nmodel = Chain(\n    Dense(2 => 10, relu),\n    Dense(10 => 20, relu),\n    Dense(20 => 5, relu),\n    Dense(5 => 1)\n)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Then define the bounds for the input variables. These will be used to calculate the activation bounds for the subsequent layers.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"init_U = [-0.5, 0.5];\ninit_L = [-1.5, -0.5];","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Now the neural network can be formulated into a MIP. Here optimization-based bound tightening is also used.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"jump_model = Model(Gurobi.Optimizer)\nset_silent(model) # set desired parameters\n\nbounds_U, bounds_L = NN_formulate!(jump_model, model, init_U, init_L; bound_tightening=\"standard\")","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Using these bounds, the model can be compressed.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"compressed, removed = NN_compress(model, init_U, init_L, bounds_U, bounds_L)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Compression can also be done without precomputed bounds.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"bounds_U, bounds_L = NN_formulate!(jump_model, model, init_U, init_L; bound_tightening=\"standard\", compress=true)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Use the JuMP model to calculate a forward pass through the network (input at the center of the domain).","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"forward_pass!(jump_model, [-1.0, 0.0])","category":"page"},{"location":"#Convolutional-neural-networks","page":"Introduction","title":"Convolutional neural networks","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The convolutional neural network requirements can be found in the CNN_formulate! documentation.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"First, create some kind of input (or load an image from your computer).","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"input = rand(Float32, 70, 50, 1, 1) # BW 70x50 image","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Then, create a convolutional neural network model satisfying the requirements:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Flux\n\nCNN_model = Flux.Chain(\n    Conv((4,3), 1 => 10, pad=(2, 1), stride=(3, 2), relu),\n    MeanPool((5,3), pad=(3, 2), stride=(2, 2)),\n    MaxPool((3,4), pad=(1, 3), stride=(3, 2)),\n    Conv((4,3), 10 => 5, pad=(2, 1), stride=(3, 2), relu),\n    MaxPool((3,4), pad=(1, 3), stride=(3, 2)),\n    Flux.flatten,\n    Dense(20 => 100, relu),\n    Dense(100 => 1)\n)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Then, create an empty JuMP model, extract the layer structure of the CNN model and finally formulate the MIP.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"jump = Model(Gurobi.Optimizer)\nset_silent(jump)\ncnns = get_structure(CNN_model, input);\nCNN_formulate!(jump, CNN_model, cnns)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Check that the JuMP model produces the same outputs as the Flux.Chain.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"vec(CNN_model(input)) ≈ image_pass!(jump, input)","category":"page"},{"location":"#How-to-use?","page":"Introduction","title":"How to use?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Using the tree ensemble optimization from this package is quite straightforward. The only parameter the user can change is the solution method: with initial constraints or with lazy constraints. In our computational tests, we have seen that the lazy constraint generation almost invariably produces models that are computationally easier to solve.  Therefore we recommend primarily using it as the solution method, but depending on your use case, trying the initial constraints might also be worthwhile.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Conversely, the choice of the best neural network bound tightening and compression procedures depends heavily on your specific use case.  Based on some limited computational tests of our own as well knowledge from the field, we can make the following general recommendations:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Wide but shallow neural networks should be preferred. The bound tightening gets exponentially harder with deeper layers.\nFor small neural network models, using the \"fast\" bound tightening option is probably the best, since the resulting formulations are easy to solve even with loose bounds.\nFor larger neural networks, \"standard\" bound tightening will produce tighter bounds but take more time. However, when using the JuMP model, the tighter bounds might make it more computationally feasible.\nFor large neural networks where the output bounds are known, \"output\" bound tightening can be used. This bound tightening is very slow but might be necessary to increase the computational feasibility of the resulting JuMP model.\nIf the model has many so-called \"dead\" neurons, creating the JuMP model by using compression is beneficial, since the formulation will have fewer constraints and the bound tightening will be faster, reducing total formulation time.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"These are only general recommendations based on limited evidence, and the user should validate the performance of each bound tightening and compression procedure in relation to her own work.","category":"page"}]
}
