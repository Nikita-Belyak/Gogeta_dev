var documenterSearchIndex = {"docs":
[{"location":"api/#Public-API","page":"Public API","title":"Public API","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"These are all of the functions and data structures that the user needs to know in order to use this package.","category":"page"},{"location":"api/#Tree-ensembles","page":"Public API","title":"Tree ensembles","text":"","category":"section"},{"location":"api/#Data-structures","page":"Public API","title":"Data structures","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"TEModel - holds the parameters from a tree ensemble model","category":"page"},{"location":"api/#Tree-model-parameter-extraction","page":"Public API","title":"Tree model parameter extraction","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"extract_evotrees_info - get the necessary parameters from an EvoTrees model","category":"page"},{"location":"api/#MIP-formulation","page":"Public API","title":"MIP formulation","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"TE_to_MIP - formulate a JuMP model from a tree ensemble without the split constraints","category":"page"},{"location":"api/#Input-optimization","page":"Public API","title":"Input optimization","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"optimize_with_initial_constraints! - solve the tree ensemble optimization problem by creating all split constraints at the beginning\noptimize_with_lazy_constraints! - solve the tree ensemble optimization problem by creating the necessary split constraints as necessary","category":"page"},{"location":"api/#Showing-the-solution","page":"Public API","title":"Showing the solution","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"get_solution - get human-readable solution in the form of upper and lower bounds for the input variables","category":"page"},{"location":"api/#Neural-networks","page":"Public API","title":"Neural networks","text":"","category":"section"},{"location":"api/#Data-structures-2","page":"Public API","title":"Data structures","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"SolverParams - holds the settings for each bound tightening solve","category":"page"},{"location":"api/#MIP-formulation-2","page":"Public API","title":"MIP formulation","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"NN_to_MIP_with_bound_tightening - formulate a JuMP model by performing simultaneous bound tightening\nNN_to_MIP_with_precomputed - formulate a JuMP model by utilizing precomputed neuron activation bounds in creating the big-M -constraints","category":"page"},{"location":"api/#Compression","page":"Public API","title":"Compression","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"compress_with_bound_tightening - perform compression by simulateous JuMP model construction and bound tightening\ncompress_with_precomputed - perform compression with precomputed neuron activation bounds","category":"page"},{"location":"api/#Forward-pass","page":"Public API","title":"Forward pass","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"forward_pass! - fix the input variables and optimize the model to get the output","category":"page"},{"location":"api/#Convolutional-neural-networks","page":"Public API","title":"Convolutional neural networks","text":"","category":"section"},{"location":"api/#Data-structures-3","page":"Public API","title":"Data structures","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"CNNStructure - container for the layer stucture of a convolutional neural network model","category":"page"},{"location":"api/#Parameter-extraction","page":"Public API","title":"Parameter extraction","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"get_structure - get layer structure from a convolutional neural network model","category":"page"},{"location":"api/#MIP-formulation-3","page":"Public API","title":"MIP formulation","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"create_MIP_from_CNN! - formulate a JuMP model from the CNN","category":"page"},{"location":"api/#Forward-pass-2","page":"Public API","title":"Forward pass","text":"","category":"section"},{"location":"api/","page":"Public API","title":"Public API","text":"image_pass! - fix the input variables and optimize the model to get the ouput","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"CurrentModule = Gogeta","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [Gogeta]","category":"page"},{"location":"reference/#Gogeta.CNNStructure","page":"Reference","title":"Gogeta.CNNStructure","text":"struct CNNStructure\n\nContainer for the layer structure of a convolutional neural network.\n\nThis structure is used for passing the CNN parameters from one function to another. This structure can be created with the get_structure -function.\n\nFields\n\nchannels: dictionary of (layer, number of channels) pairs for convolutional or pooling layers\ndims: dictionary of (layer, (# of rows, # of columns)) pairs for convolutional or pooling layers\ndense_lengths: dictionary of (layer, # of neurons) pairs for dense and flatten layers\nconv_inds: vector of the convolutional layer indices\nmaxpool_inds_inds: vector of the maxpool layer indices\nmeanpool_inds: vector of the meanpool layer indices\nflatten_ind: index of the Flux.flatten layer\ndense_inds: vector of the dense layer indices\n\n```\n\n\n\n\n\n","category":"type"},{"location":"reference/#Gogeta.SolverParams","page":"Reference","title":"Gogeta.SolverParams","text":"SolverParams\n\nParameters to be used by the solver.\n\nFields\n\nsolver: has to be \"Gurobi\" or \"GLPK\"\nsilent: is the solver log shown\nthreads: use 0 for solver default\nrelax: linear relaxation for the MIP\ntime_limit: time limit for each optimization in the model\n\nExamples\n\njulia> solver_params = SolverParams(solver=\"Gurobi\", silent=true, threads=0, relax=false, time_limit=0);\n\n\n\n\n\n","category":"type"},{"location":"reference/#Gogeta.TEModel","page":"Reference","title":"Gogeta.TEModel","text":"struct TEModel\n\nUniversal datatype for storing information about a Tree Ensemble Model. This is the datatype that is used when creating the integer optimization problem from a tree ensemble.\n\nDifferent tree models (EvoTrees, XGBoost, RandomForest) require individual conversion functions to this datatype.\n\nFields\n\nn_trees: number of trees in the ensemble\nn_feats: number of features (input variables) in the model\nn_leaves: number of leaves on each tree\nleaves: indices of the leaves on each tree\nsplits: [feature, splitpoint index] pairs accessible by [tree, node]\nsplits_ordered: splitpoints ordered by split value for each feature\nn_splits: number of splitpoints for each feature\npredictions: prediction of each node (zero for nodes that are not leaves)\nsplit_nodes: boolean array containing information whether a node is a split node or not\n\nSplitpoints is the set of unique condition values from the ensemble. Each node is associated with a condition value.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Gogeta.NN_to_MIP_with_bound_tightening-Tuple{Flux.Chain, Any, Any, Any}","page":"Reference","title":"Gogeta.NN_to_MIP_with_bound_tightening","text":"function NN_to_MIP_with_bound_tightening(NN_model::Flux.Chain, U_in, L_in, solver_params; bound_tightening=\"fast\", U_out=nothing, L_out=nothing, silent=false)\n\nCreates a mixed-integer optimization problem from a Flux.Chain model. In this version, the neuron activation bounds are calculated as the model is being created.\n\nReturns the resulting JuMP model and the computed activation bounds.\n\nParameters\n\nNN_model: the neural network as a Flux.Chain\nU_in: upper bounds of the input neurons\nL_in: lower bounds of the input neurons\nsolver_params: a SolverParams struct\n\nOptional arguments\n\nbound_tightening: \"fast\", \"standard\" or \"output\"\nsilent: controls the output logs\nU_out: upper activation bounds for the output layer (must be set if bound_tightening=\"output\")\nL_out: lower activation bounds for the output layer (must be set if bound_tightening=\"output\")\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.NN_to_MIP_with_precomputed-Tuple{Flux.Chain, Vararg{Any, 5}}","page":"Reference","title":"Gogeta.NN_to_MIP_with_precomputed","text":"function NN_to_MIP_with_precomputed(NN_model::Flux.Chain, U_in, L_in, solver_params, U_bounds, L_bounds; silent=false)\n\nCreates a mixed-integer optimization problem from a Flux.Chain model. In this version, the neuron activation bounds must be given as arguments.\n\nReturns the resulting JuMP model.\n\nParameters\n\nNN_model: the neural network as a Flux.Chain\nU_in: upper bounds of the input neurons\nL_in: lower bounds of the input neurons\nsolver_params: a SolverParams struct\nU_bounds: precomputed upper activation bounds for each layer\nL_bounds: precomputed lower activation bounds for each layer\n\nOptional arguments\n\nsilent: controls the output logs\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.TE_to_MIP-Tuple{TEModel, Any, Any}","page":"Reference","title":"Gogeta.TE_to_MIP","text":"function TE_to_MIP(TE::TEModel, optimizer, objective)\n\nCreates a JuMP model opt_model based on the given tree ensemble. Returns opt_model.\n\nThe JuMP model is created without the split constraints.\n\nArguments\n\nTE: A tree ensemble model in the universal data type TEModel. \noptimizer: Optimizer object that will be given to the JuMP model.\nobjective: MINSENSE or MAXSENSE.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.build_model!-NTuple{4, Any}","page":"Reference","title":"Gogeta.build_model!","text":"function build_model!(W, b, K, neurons)\n\nBuilds a new Flux.Chain model from the given weights and biases.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.calculate_bounds-Tuple{JuMP.Model, Vararg{Any, 5}}","page":"Reference","title":"Gogeta.calculate_bounds","text":"function calculate_bounds(model::JuMP.Model, layer, neuron, W, b, neurons; layers_removed=0)\n\nCalculates the upper and lower activation bounds for a neuron in a ReLU-activated neural network.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.children-Tuple{Int64, Dict, Int64}","page":"Reference","title":"Gogeta.children","text":"function children(id::Int, leaf_dict::Dict, max::Int)\n\nFinds the leaf indices of the children leaves of node id in a binary tree.\n\nReturns an array of the leaf indices.\n\nArguments\n\nid: Index of the node in a binary tree. Indexing starts from one and follows level order.\nleaf_dict: A dictionary (map) of the leaf indices accessible by the node indices.\nmax: Biggest possible node id in the tree. Used to terminate the search.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.compress_with_bound_tightening-Tuple{Flux.Chain, Any, Any, Any}","page":"Reference","title":"Gogeta.compress_with_bound_tightening","text":"function compress_with_bound_tightening(NN_model::Flux.Chain, U_in, L_in, solver_params; bound_tightening=\"fast\", silent=false)\n\nCreates a compressed version of the neural network model Flux.Chain given as input. This is accomplished by identifying inactive and stabily active neurons. This version computes the bounds as the network is being compressed.\n\nReturn the compressed model, the list of removed neurons, the JuMP model and computed bounds.\n\nParameters\n\nNN_model: the neural network as a Flux.Chain\nU_in: upper bounds of the input neurons\nL_in: lower bounds of the input neurons\nsolver_params: a SolverParams struct\n\nOptional arguments\n\nbound_tightening: \"fast\" or \"standard\"\nsilent: controls the output logs\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.compress_with_precomputed-Tuple{Flux.Chain, Vararg{Any, 4}}","page":"Reference","title":"Gogeta.compress_with_precomputed","text":"function compress_with_precomputed(NN_model::Flux.Chain, U_in, L_in, U_bounds, L_bounds; silent=true)\n\nCreates a compressed version of the neural network model Flux.Chain given as input. This is accomplished by identifying inactive and stabily active neurons.\n\nReturn the compressed model and the list of removed neurons.\n\nParameters\n\nNN_model: the neural network as a Flux.Chain\nU_in: upper bounds of the input neurons\nL_in: lower bounds of the input neurons\nU_bounds: precomputed upper activation bounds for each layer\nL_bounds: precomputed lower activation bounds for each layer\n\nOptional arguments\n\nsilent: controls the output logs\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.copy_model-Tuple{Any, Any}","page":"Reference","title":"Gogeta.copy_model","text":"function copy_model(input_model, solver_params)\n\nCopies a JuMP model. Solver has to be specified for each new copy. Used for parallelization.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.create_MIP_from_CNN!-Tuple{JuMP.Model, Flux.Chain, CNNStructure}","page":"Reference","title":"Gogeta.create_MIP_from_CNN!","text":"function create_MIP_from_CNN!(jump_model::JuMP.Model, CNN_model::Flux.Chain, cnnstruct::CNNStructure)\n\nCreates a mixed-integer optimization problem from a Flux.Chain convolutional neural network model. The optimization formulation is saved in the JuMP.Model given as an input.\n\nThe convolutional neural network must follow a certain structure:\n\nIt must consist of (in order) convolutional and pooling layers, a Flux.flatten layer and finally dense layers\nI.e. allowed layer types: Conv, MaxPool, MeanPool, Flux.flatten, Dense\nThe activation function for all of the convolutional layers and the dense layers must be ReLU\nThe last dense layer must use the identity activation function\nInput size, filter size, stride and padding can be chosen freely\n\nParameters\n\njump_model: an empty optimization model where the formulation will be saved\nCNN_model: Flux.Chain containing the CNN\ncnnstruct: holds the layer structure of the CNN\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.extract_evotrees_info-Tuple{Any}","page":"Reference","title":"Gogeta.extract_evotrees_info","text":"extract_evotrees_info(evo_model; tree_limit=length(evo_model.trees))\n\nGets the data required for constructing the corresponding MIP from an EvoTrees model evo_model.  Returns a custom datatype TEModel which contains the necessary information.\n\nArguments\n\nevo_model: A trained EvoTrees tree ensemble model.\n\nOptional arguments\n\ntree_limit: only first n trees specified by the argument will be used\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.formulate_and_compress-Tuple{Flux.Chain, Any, Any}","page":"Reference","title":"Gogeta.formulate_and_compress","text":"function formulate_and_compress(NN_model::Flux.Chain, U_in, L_in; U_bounds=nothing, L_bounds=nothing, U_out=nothing, L_out=nothing, solver_params=nothing, bound_tightening=\"fast\", compress=false, silent=false)\n\nCreates a mixed-integer optimization problem from a Flux.Chain model.\n\nThe parameters are used to specify what kind of bound tightening and compression will be used.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.forward_pass!-Tuple{JuMP.Model, Any}","page":"Reference","title":"Gogeta.forward_pass!","text":"function forward_pass!(jump_model::JuMP.Model, input)\n\nCalculates the output of a neural network -representing JuMP model given some input.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.get_solution-Tuple{JuMP.Model, TEModel}","page":"Reference","title":"Gogeta.get_solution","text":"function get_solution(model::JuMP.Model, TE::TEModel)\n\nFinds the upper and lower bounds for each input variable given the optimized model.\n\nReturns the bounds for each feature in an array.\n\nArguments\n\nmodel: The optimized JuMP model.\nTE: Struct of type TEModel containing information about the tree ensemble.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.get_structure-Tuple{Flux.Chain, Array{Float32, 4}}","page":"Reference","title":"Gogeta.get_structure","text":"function get_structure(CNN_model::Flux.Chain, input::Array{Float32, 4})\n\nExtract the layer structure of a convolutional neural network. The input image is needed to calculate the correct sizes for the hidden 2-dimensional layers.\n\nReturns a CNNStructure struct.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.image_pass!-Tuple{JuMP.Model, Array{Float32, 4}, CNNStructure, Int64}","page":"Reference","title":"Gogeta.image_pass!","text":"function image_pass!(jump_model::JuMP.Model, input::Array{FLoat32, 4}, cnnstruct::CNNStructure, layer::Int)\n\nDebugging version\n\nForward pass an image through the JuMP model representing a convolutional neural network.\n\nReturns the output of the layer with index given as input.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.image_pass!-Tuple{JuMP.Model, Array{Float32, 4}}","page":"Reference","title":"Gogeta.image_pass!","text":"function image_pass!(jump_model::JuMP.Model, input::Array{Float32, 4})\n\nForward pass an image through the JuMP model representing a convolutional neural network.\n\nReturns the output of the network, i.e., a vector of the activations of the last dense layer neurons.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.init_TEModel!-Tuple{TEModel}","page":"Reference","title":"Gogeta.init_TEModel!","text":"function init_TEModel!(TE::TEModel)\n\nPrecompute child leaves which are needed for generating the split constraints. Changes child_leaves field of the TEModel.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.optimize_with_initial_constraints!-Tuple{JuMP.Model, TEModel}","page":"Reference","title":"Gogeta.optimize_with_initial_constraints!","text":"function optimize_with_initial_constraints!(opt_model::JuMP.Model, TE::TEModel)\n\nAdds all split constraints to the formulation and then solves the MIP.\n\nArguments\n\nopt_model: A JuMP model containing the formulation.\nTE: A tree ensemble model in the universal data type TEModel. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.optimize_with_lazy_constraints!-Tuple{JuMP.Model, TEModel}","page":"Reference","title":"Gogeta.optimize_with_lazy_constraints!","text":"function optimize_with_lazy_constraints!(opt_model::JuMP.Model, TE::TEModel)\n\nSolves the optimization model by utilizing lazy constraints. This means that the split constraints are added one-by-one for each tree.\n\nArguments\n\nopt_model: A JuMP model containing the formulation.\nTE: A tree ensemble model in the universal data type TEModel. \n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.prune!-NTuple{8, Any}","page":"Reference","title":"Gogeta.prune!","text":"function prune!(W, b, removed_neurons, layers_removed, neuron_count, layer, bounds_U, bounds_L)\n\nRemoves stabily active or inactive neurons in a network by updating the weights and the biases and the removed neurons list accordingly.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Gogeta.set_solver_params!-Tuple{Any, Any}","page":"Reference","title":"Gogeta.set_solver_params!","text":"function set_solver_params!(model, params)\n\nSet the parameters of a JuMP model. Solver and its parameters have to be specified for each new model copy. Used for parallelization.\n\n\n\n\n\n","category":"method"},{"location":"#Gogeta.jl","page":"Introduction","title":"Gogeta.jl","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Gogeta is a package that enables the user to formulate machine-learning models as mathematical programming problems.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Currently supported models are Flux.Chain ReLU-activated neural networks (dense and convolutional) and EvoTrees tree ensemble models.","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> Pkg.add(\"Gogeta\")","category":"page"},{"location":"#Getting-started","page":"Introduction","title":"Getting started","text":"","category":"section"},{"location":"#Tree-ensembles","page":"Introduction","title":"Tree ensembles","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"First, one must create and train an EvoTrees tree ensemble model.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using EvoTrees\n\nconfig = EvoTreeRegressor(nrounds=500, max_depth=5);\nevo_model = fit_evotree(config; x_train, y_train);","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Then the parameters can be extracted from the trained tree ensemble and used to create a JuMP model containing the tree ensemble MIP formulation.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Gurobi\nusing Gogeta\n\n# Extract data from EvoTrees model\n\nuniversal_tree_model = extract_evotrees_info(evo_model);\n\n# Create JuMP model\nopt_model = TE_to_MIP(universal_tree_model, Gurobi.Optimizer(), MIN_SENSE);","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"There are two ways of optimizing the JuMP model: either by 1) creating the full set of split constraints before optimizing, or 2) using lazy constraints to generate only the necessary ones during the solution process.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"optimize_with_lazy_constraints!(opt_model, universal_tree_model)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"optimize_with_initial_constraints!(opt_model, universal_tree_model)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The optimal solution (minimum and maximum values for each of the input variables) can be queried after the optimization.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"get_solution(opt_model, universal_tree_model)\nobjective_value(opt_model)","category":"page"},{"location":"#Neural-networks","page":"Introduction","title":"Neural networks","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"With neural networks, the hidden layers must use the ReLU activation function, and the output layer must use the identity activation.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"These neural networks can be formulated into mixed-integer optimization problems.  Along with formulation, the neuron activation bounds can be calculated, which improves computational performance as well as enables compression.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The network is compressed by pruning neurons that are either stabily active or inactive. The activation bounds are used to identify these neurons.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"First, create a neural network model satisfying the requirements:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Flux\n\nmodel = Chain(\n    Dense(2 => 10, relu),\n    Dense(10 => 20, relu),\n    Dense(20 => 5, relu),\n    Dense(5 => 1)\n)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Then define the bounds for the input variables. These will be used to calculate the activation bounds for the subsequent layers.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"init_U = [-0.5, 0.5];\ninit_L = [-1.5, -0.5];","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"One needs to provide parameters for the solver. In this case Gurobi solver is used with console logging off, default thread count, linear relaxation off and infinite time limit.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"solver_params = SolverParams(solver=\"Gurobi\", silent=true, threads=0, relax=false, time_limit=0);","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Then the neural network can be formulated into a MIP. Here bound tightening is also used.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"nn_jump, U_correct, L_correct = NN_to_MIP_with_bound_tightening(model, init_U, init_L, solver_params; bound_tightening=\"standard\");","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Using these bounds, the model can be compressed.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"compressed, removed = compress_with_precomputed(model, init_U, init_L, U_correct, L_correct);","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Compression can also be done without precomputed bounds.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"jump_model, compressed_model, removed_neurons, bounds_U, bounds_L = compress_with_bound_tightening(model, init_U, init_L,solver_params; bound_tightening=\"standard\");","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Use the JuMP model to calculate a forward pass through the network (input at the center of the domain).","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"forward_pass!(jump_model, [-1.0, 0.0])","category":"page"},{"location":"#Convolutional-neural-networks","page":"Introduction","title":"Convolutional neural networks","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The convolutional neural network requirements can be found in the create_MIP_from_CNN! documentation.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"First, create some kind of input (or load an image from your computer).","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"input = rand(Float32, 70, 50, 1, 1) # BW 70x50 image","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Then, create a convolutional neural network model satisfying the requirements:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Flux\n\nCNN_model = Flux.Chain(\n    Conv((4,3), 1 => 10, pad=(2, 1), stride=(3, 2), relu),\n    MeanPool((5,3), pad=(3, 2), stride=(2, 2)),\n    MaxPool((3,4), pad=(1, 3), stride=(3, 2)),\n    Conv((4,3), 10 => 5, pad=(2, 1), stride=(3, 2), relu),\n    MaxPool((3,4), pad=(1, 3), stride=(3, 2)),\n    Flux.flatten,\n    Dense(20 => 100, relu),\n    Dense(100 => 1)\n)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Then, create an empty JuMP model, extract the layer structure of the CNN model and finally formulate the MIP.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"jump = Model(Gurobi.Optimizer)\nset_silent(jump)\ncnns = get_structure(CNN_model, input);\ncreate_MIP_from_CNN!(jump, CNN_model, cnns)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Check that the JuMP model produces the same outputs as the Flux.Chain.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"vec(CNN_model(input)) ≈ image_pass!(jump, input)","category":"page"},{"location":"#How-to-use?","page":"Introduction","title":"How to use?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Using the tree ensemble optimization from this package is quite straightforward. The only parameter the user can change is the solution method: with initial constraints or with lazy constraints. In our computational tests, we have seen that the lazy constraint generation almost invariably produces models that are computationally easier to solve.  Therefore we recommend primarily using it as the solution method, but depending on your use case, trying the initial constraints might also be worthwhile.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Conversely, the choice of the best neural network bound tightening and compression procedures depends heavily on your specific use case.  Based on some limited computational tests of our own as well knowledge from the field, we can make the following general recommendations:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Wide but shallow neural networks should be preferred. The bound tightening gets exponentially harder with deeper layers.\nFor small neural network models, using the \"fast\" bound tightening option is probably the best, since the resulting formulations are easy to solve even with loose bounds.\nFor larger neural networks, \"standard\" bound tightening will produce tighter bounds but take more time. However, when using the JuMP model, the tighter bounds might make it more computationally feasible.\nFor large neural networks where the output bounds are known, \"output\" bound tightening can be used. This bound tightening is very slow but might be necessary to increase the computational feasibility of the resulting JuMP model.\nIf the model has many so-called \"dead\" neurons, creating the JuMP model by using compression is beneficial, since the formulation will have fewer constraints and the bound tightening will be faster, reducing total formulation time.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"These are only general recommendations based on limited evidence, and the user should validate the performance of each bound tightening and compression procedure in relation to her own work.","category":"page"}]
}
